{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f2ec31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4a486df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/sods_limpo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc46fa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idade</th>\n",
       "      <th>genero</th>\n",
       "      <th>etnia</th>\n",
       "      <th>pcd</th>\n",
       "      <th>vive_no_brasil</th>\n",
       "      <th>estado_moradia</th>\n",
       "      <th>nivel_ensino</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tempo_experiencia_dados</th>\n",
       "      <th>linguagens_preferidas</th>\n",
       "      <th>bancos_de_dados</th>\n",
       "      <th>cloud_preferida</th>\n",
       "      <th>cargo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Não</td>\n",
       "      <td>True</td>\n",
       "      <td>Distrito Federal (DF)</td>\n",
       "      <td>Pós-graduação</td>\n",
       "      <td>Computação / Engenharia de Software / Sistemas...</td>\n",
       "      <td>de 1 a 2 anos</td>\n",
       "      <td>r</td>\n",
       "      <td>postgresql, oracle, mysql, sql server</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>DBA/Administrador de Banco de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>True</td>\n",
       "      <td>Distrito Federal (DF)</td>\n",
       "      <td>Pós-graduação</td>\n",
       "      <td>Computação / Engenharia de Software / Sistemas...</td>\n",
       "      <td>de 3 a 4 anos</td>\n",
       "      <td>python</td>\n",
       "      <td>postgresql, mysql, oracle, db2</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>Desenvolvedor/ Engenheiro de Software/ Analist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>True</td>\n",
       "      <td>Minas Gerais (MG)</td>\n",
       "      <td>Doutorado ou Phd</td>\n",
       "      <td>Estatística/ Matemática / Matemática Computaci...</td>\n",
       "      <td>de 4 a 6 anos</td>\n",
       "      <td>python</td>\n",
       "      <td>google bigquery</td>\n",
       "      <td>Não sei opinar</td>\n",
       "      <td>Cientista de Dados/Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>True</td>\n",
       "      <td>Pará (PA)</td>\n",
       "      <td>Pós-graduação</td>\n",
       "      <td>Computação / Engenharia de Software / Sistemas...</td>\n",
       "      <td>Não tenho experiência na área de dados</td>\n",
       "      <td>python</td>\n",
       "      <td>microsoft access</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>Desenvolvedor/ Engenheiro de Software/ Analist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Não</td>\n",
       "      <td>True</td>\n",
       "      <td>Ceará (CE)</td>\n",
       "      <td>Pós-graduação</td>\n",
       "      <td>Ciências Biológicas/ Farmácia/ Medicina/ Área ...</td>\n",
       "      <td>Não tenho experiência na área de dados</td>\n",
       "      <td>python</td>\n",
       "      <td>google bigquery</td>\n",
       "      <td>Google Cloud (GCP)</td>\n",
       "      <td>Professor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idade     genero   etnia  pcd  vive_no_brasil         estado_moradia  \\\n",
       "0     39  Masculino   Parda  Não            True  Distrito Federal (DF)   \n",
       "1     53  Masculino  Branca  Não            True  Distrito Federal (DF)   \n",
       "2     27  Masculino  Branca  Não            True      Minas Gerais (MG)   \n",
       "3     46   Feminino  Branca  Não            True              Pará (PA)   \n",
       "4     32   Feminino   Parda  Não            True             Ceará (CE)   \n",
       "\n",
       "       nivel_ensino                                           formacao  \\\n",
       "0     Pós-graduação  Computação / Engenharia de Software / Sistemas...   \n",
       "1     Pós-graduação  Computação / Engenharia de Software / Sistemas...   \n",
       "2  Doutorado ou Phd  Estatística/ Matemática / Matemática Computaci...   \n",
       "3     Pós-graduação  Computação / Engenharia de Software / Sistemas...   \n",
       "4     Pós-graduação  Ciências Biológicas/ Farmácia/ Medicina/ Área ...   \n",
       "\n",
       "                  tempo_experiencia_dados linguagens_preferidas  \\\n",
       "0                           de 1 a 2 anos                     r   \n",
       "1                           de 3 a 4 anos                python   \n",
       "2                           de 4 a 6 anos                python   \n",
       "3  Não tenho experiência na área de dados                python   \n",
       "4  Não tenho experiência na área de dados                python   \n",
       "\n",
       "                         bancos_de_dados            cloud_preferida  \\\n",
       "0  postgresql, oracle, mysql, sql server  Amazon Web Services (AWS)   \n",
       "1         postgresql, mysql, oracle, db2  Amazon Web Services (AWS)   \n",
       "2                        google bigquery             Não sei opinar   \n",
       "3                       microsoft access  Amazon Web Services (AWS)   \n",
       "4                        google bigquery         Google Cloud (GCP)   \n",
       "\n",
       "                                               cargo  \n",
       "0                DBA/Administrador de Banco de Dados  \n",
       "1  Desenvolvedor/ Engenheiro de Software/ Analist...  \n",
       "2                  Cientista de Dados/Data Scientist  \n",
       "3  Desenvolvedor/ Engenheiro de Software/ Analist...  \n",
       "4                                          Professor  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839875a",
   "metadata": {},
   "source": [
    "## Extraindo Informações Sobre As Variaveis Categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7882e8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genero</th>\n",
       "      <th>etnia</th>\n",
       "      <th>pcd</th>\n",
       "      <th>estado_moradia</th>\n",
       "      <th>nivel_ensino</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tempo_experiencia_dados</th>\n",
       "      <th>linguagens_preferidas</th>\n",
       "      <th>bancos_de_dados</th>\n",
       "      <th>cloud_preferida</th>\n",
       "      <th>cargo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2981</td>\n",
       "      <td>2981</td>\n",
       "      <td>2981</td>\n",
       "      <td>2981</td>\n",
       "      <td>2981</td>\n",
       "      <td>2981</td>\n",
       "      <td>2981</td>\n",
       "      <td>2981</td>\n",
       "      <td>2981</td>\n",
       "      <td>2981</td>\n",
       "      <td>2981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>1429</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Masculino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>São Paulo (SP)</td>\n",
       "      <td>Graduação/Bacharelado</td>\n",
       "      <td>Computação / Engenharia de Software / Sistemas...</td>\n",
       "      <td>de 1 a 2 anos</td>\n",
       "      <td>python</td>\n",
       "      <td>google bigquery</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>Analista de Dados/Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2212</td>\n",
       "      <td>1917</td>\n",
       "      <td>2927</td>\n",
       "      <td>1220</td>\n",
       "      <td>1143</td>\n",
       "      <td>1102</td>\n",
       "      <td>906</td>\n",
       "      <td>2581</td>\n",
       "      <td>227</td>\n",
       "      <td>1153</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           genero   etnia   pcd  estado_moradia           nivel_ensino  \\\n",
       "count        2981    2981  2981            2981                   2981   \n",
       "unique          3       7     3              23                      7   \n",
       "top     Masculino  Branca   Não  São Paulo (SP)  Graduação/Bacharelado   \n",
       "freq         2212    1917  2927            1220                   1143   \n",
       "\n",
       "                                                 formacao  \\\n",
       "count                                                2981   \n",
       "unique                                                 10   \n",
       "top     Computação / Engenharia de Software / Sistemas...   \n",
       "freq                                                 1102   \n",
       "\n",
       "       tempo_experiencia_dados linguagens_preferidas  bancos_de_dados  \\\n",
       "count                     2981                  2981             2981   \n",
       "unique                       7                    21             1429   \n",
       "top              de 1 a 2 anos                python  google bigquery   \n",
       "freq                       906                  2581              227   \n",
       "\n",
       "                  cloud_preferida                           cargo  \n",
       "count                        2981                            2981  \n",
       "unique                          5                              18  \n",
       "top     Amazon Web Services (AWS)  Analista de Dados/Data Analyst  \n",
       "freq                         1153                             639  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include='object').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "244d2061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['postgresql, oracle, mysql, sql server',\n",
       " 'postgresql, mysql, oracle, db2',\n",
       " 'google bigquery',\n",
       " 'microsoft access',\n",
       " 'sql server',\n",
       " 'postgresql, sqlite, amazon athena',\n",
       " 'mysql, postgresql, sql server',\n",
       " 'sql server, hive, postgresql, splunk, databricks',\n",
       " 'mysql, oracle, google bigquery',\n",
       " 'oracle, mongodb, postgresql, databricks, hive',\n",
       " 'google bigquery, dynamodb',\n",
       " 'mongodb, db2, databricks, microsoft access, sql server, mariadb, oracle, mysql',\n",
       " 'amazon athena, amazon redshift, databricks, mysql, s3',\n",
       " 'postgresql, sql server, sqlite',\n",
       " 'google bigquery, google cloud storage',\n",
       " 'mysql',\n",
       " 'amazon redshift, mongodb, amazon aurora ou rds',\n",
       " 'microsoft access, sql server',\n",
       " 'clickhouse',\n",
       " 'amazon redshift, oracle, postgresql, amazon athena',\n",
       " 'base de dados local',\n",
       " 'mongodb, redis, postgresql, elaticsearch, s3',\n",
       " 'mysql, sql server, postgresql, sqlite',\n",
       " 'postgresql',\n",
       " 'hive, elaticsearch, amazon aurora ou rds, sql server, presto, s3, mysql, amazon athena, dynamodb, amazon redshift, postgresql, oracle',\n",
       " 's3',\n",
       " 'sql server, mysql, postgresql, google bigquery',\n",
       " 'splunk, amazon athena, google bigquery',\n",
       " 'sap hana, db2, hive, databricks, mysql, amazon redshift, google bigquery, amazon athena, postgresql, s3, presto, sql server, mongodb',\n",
       " 'google bigquery, mongodb, postgresql',\n",
       " 'google bigquery, mysql',\n",
       " 'amazon redshift, sql server, oracle',\n",
       " 'databricks, google bigquery',\n",
       " 'sql server, oracle, s3, sqlite, amazon athena, hive',\n",
       " 's3, amazon redshift, amazon athena, mysql, amazon aurora ou rds',\n",
       " 'oracle',\n",
       " 'google bigquery, sap hana',\n",
       " 'mysql, amazon redshift, mariadb, s3, elaticsearch, sqlite',\n",
       " 'não uso',\n",
       " 'postgresql, snowflake, dremio',\n",
       " 'postgresql, sql server, google bigquery, mysql, cassandra, databricks',\n",
       " 'amazon athena',\n",
       " 'sql server, databricks, s3, mongodb',\n",
       " 'interno',\n",
       " 'hive, presto',\n",
       " 'mysql, google bigquery, elaticsearch',\n",
       " 'postgresql, sql server',\n",
       " 'sql server, sybase, oracle, databricks',\n",
       " 's3, mysql, sql server, databricks, oracle, snowflake, amazon athena, db2, sap hana, google bigquery',\n",
       " 'databricks, s3',\n",
       " 'databricks, sap hana',\n",
       " 'amazon athena, s3, databricks',\n",
       " 'oracle, snowflake',\n",
       " 'sqlite, mysql, postgresql',\n",
       " 's3, amazon redshift, mysql, amazon athena, sql server, postgresql',\n",
       " 'sap hana',\n",
       " 'mysql, firebase',\n",
       " 'bases excel e csv extraídas direto no site',\n",
       " 'metabase',\n",
       " 'google bigquery, postgresql, sqlite, sql server, mysql, mongodb',\n",
       " 'google bigquery, postgresql',\n",
       " 'amazon athena, s3, presto, postgresql',\n",
       " 'amazon redshift, s3, postgresql',\n",
       " 'postgresql, amazon athena, s3, amazon aurora ou rds',\n",
       " 'postgresql, google bigquery, snowflake, dynamodb, databricks',\n",
       " 'excel',\n",
       " 'mysql, mariadb, sql server, postgresql',\n",
       " 'datomic, hive, splunk, amazon redshift, postgresql, dynamodb, presto, s3, cruxdb',\n",
       " 'oracle, s3, dynamodb, amazon redshift, amazon athena',\n",
       " 'sql server, progress',\n",
       " 's3, amazon redshift, cassandra',\n",
       " 's3, amazon athena',\n",
       " 'databricks, sql server',\n",
       " 'databricks',\n",
       " 'amazon aurora ou rds, mysql, snowflake, oracle, amazon redshift, sql server, elaticsearch, amazon athena, s3, databricks, hive, google bigquery, cassandra',\n",
       " 'databricks, sql server, sqlite, mysql',\n",
       " 'oracle, amazon redshift, snowflake, postgresql',\n",
       " 'postgresql, amazon redshift, dynamodb',\n",
       " 'microsoft access, amazon redshift, sql server',\n",
       " 'databricks, snowflake, s3',\n",
       " 'sql server, s3, mysql, amazon athena',\n",
       " 'postgresql, mysql, sql server',\n",
       " 'mongodb, sap hana, google bigquery, dynamodb',\n",
       " 'microsoft access, google bigquery',\n",
       " 'postgresql, google bigquery, mongodb',\n",
       " 'amazon redshift, snowflake, databricks',\n",
       " 'sqlite, hive, google bigquery, postgresql, mysql, mongodb',\n",
       " 'firebase',\n",
       " 'dali - hpcc system',\n",
       " 'oracle, databricks',\n",
       " 'mysql, sqlite, s3',\n",
       " 'sql server, amazon aurora ou rds, s3, amazon redshift, mongodb, sqlite, databricks, snowflake, google bigquery, postgresql, oracle, amazon athena, mysql',\n",
       " 'mysql, sql server',\n",
       " 'postgresql, google bigquery, sap hana',\n",
       " 'dados não estruturados',\n",
       " 'amazon athena, amazon redshift, mysql, amazon aurora ou rds',\n",
       " 'snowflake',\n",
       " 's3, amazon redshift, db2, mysql',\n",
       " 'amazon aurora ou rds, elaticsearch, sql server, postgresql, dynamodb, amazon redshift, presto, amazon athena, s3',\n",
       " 'elaticsearch, sql server',\n",
       " 'sql server, snowflake',\n",
       " 'mysql, sap hana, postgresql, sql server, mongodb, google bigquery',\n",
       " 'amazon aurora ou rds, s3, mongodb, postgresql',\n",
       " 'postgresql, oracle, mysql, s3',\n",
       " 'google bigquery, google firestore',\n",
       " 'postgresql, google bigquery, databricks',\n",
       " 'sql server, db2',\n",
       " 'amazon redshift, amazon aurora ou rds, s3',\n",
       " 'db2, sql server',\n",
       " 'sap hana, snowflake',\n",
       " 'microsoft access, oracle, sql server',\n",
       " 'postgresql, sql server, databricks',\n",
       " 'postgresql, amazon athena, firebase, mongodb, google bigquery, amazon redshift, s3',\n",
       " 'snowflake, s3, sistema de crm',\n",
       " 'amazon redshift, google bigquery',\n",
       " 'snowflake, elaticsearch, google bigquery, databricks, amazon athena, s3, mongodb, redis, dynamodb, postgresql, hive',\n",
       " 's3, amazon aurora ou rds, sql server',\n",
       " 'databricks, mysql, amazon redshift, postgresql, s3',\n",
       " 'elaticsearch, mysql, postgresql, amazon athena, amazon redshift, amazon aurora ou rds, s3, dynamodb',\n",
       " 'mongodb',\n",
       " 'sql server, postgresql, google bigquery',\n",
       " 'cassandra',\n",
       " 'oracle, postgresql, sql server',\n",
       " 'mysql, postgresql',\n",
       " 'google firestore',\n",
       " 'hive, mysql, dynamodb',\n",
       " 's3, databricks, snowflake',\n",
       " 'sql server, microsoft access',\n",
       " 'google bigquery, hive, cloud spanner',\n",
       " 'oracle, mysql',\n",
       " 'amazon athena, neo4j, s3',\n",
       " 'neo4j, mongodb, snowflake, amazon aurora ou rds, mysql, elaticsearch, sqlite, mariadb, hbase, hive, sql server, dynamodb, oracle, cassandra, s3, presto, amazon redshift, databricks, amazon athena',\n",
       " 'mysql, amazon aurora ou rds, mongodb, postgresql',\n",
       " 'google bigquery, postgresql, s3',\n",
       " 'oracle, sql server, mysql',\n",
       " 'google bigquery, sql server, mysql',\n",
       " 'databricks, hive, postgresql, presto, sql server',\n",
       " 'sqlite',\n",
       " 'sharepoint',\n",
       " 'sql server, amazon redshift',\n",
       " 'microsoft access, oracle',\n",
       " 'oracle, presto, neo4j, hbase, firebase, google bigquery, elaticsearch, snowflake, sqlite, dynamodb, redis, amazon aurora ou rds, mysql, amazon athena, amazon redshift, mongodb, sql server, hive, s3',\n",
       " 'dynamodb, sql server',\n",
       " 'postgresql, mysql',\n",
       " 'sybase, postgresql, sql server',\n",
       " 'hive, teradata',\n",
       " 'mysql, s3, amazon aurora ou rds, sql server, databricks, postgresql',\n",
       " 'sap hana, google bigquery, sql server, mysql',\n",
       " 'postgresql, elaticsearch, google bigquery',\n",
       " 'amazon aurora ou rds, amazon athena',\n",
       " 'mongodb, postgresql, google bigquery',\n",
       " 'google bigquery, amazon redshift',\n",
       " 'postgresql, splunk, elaticsearch, db2',\n",
       " 'synapse',\n",
       " 'amazon redshift, s3',\n",
       " 'db2, google bigquery, firebase, sql server, mongodb',\n",
       " 'postgresql, presto, databricks, impala',\n",
       " 'mariadb, databricks',\n",
       " 'google bigquery, sql server, oracle, snowflake, s3, amazon aurora ou rds, mysql',\n",
       " 'hive, google bigquery, s3, amazon redshift',\n",
       " 'databricks, sql server, mysql',\n",
       " 'sql server, splunk',\n",
       " 'google bigquery, dynamodb, datomic, databricks, splunk',\n",
       " 'amazon redshift',\n",
       " 's3, amazon aurora ou rds, sql server, postgresql, amazon redshift, presto, hive, amazon athena, databricks, mongodb',\n",
       " 's3, amazon athena, dynamodb, amazon redshift, google bigquery',\n",
       " 'hive, databricks, google bigquery',\n",
       " 'amazon redshift, mysql, databricks, s3',\n",
       " 'sql server, oracle, microsoft access',\n",
       " 'sql server, oracle, mysql, mongodb',\n",
       " 'sql server, mysql',\n",
       " 'sql server, sqlite, snowflake, sap hana',\n",
       " 'api',\n",
       " 'sql server, oracle',\n",
       " 'sql server, s3, postgresql',\n",
       " 'sap hana, google bigquery',\n",
       " 'mysql, databricks',\n",
       " 'snowflake, elaticsearch, redis, amazon redshift',\n",
       " 'google analytics',\n",
       " 'postgresql, s3',\n",
       " 'sql server, mongodb, neo4j, postgresql, mysql',\n",
       " 'sql server, postgresql, mysql, snowflake',\n",
       " 'amazon athena, google bigquery, amazon aurora ou rds, mysql, elaticsearch, postgresql, mongodb',\n",
       " 'nsa',\n",
       " 'mysql, firebase, sql server, firebird',\n",
       " 'sql server, oracle, mysql, microsoft access, postgresql, mongodb',\n",
       " 'databricks, redis, elaticsearch, hive',\n",
       " 's3, amazon redshift',\n",
       " 'oracle, postgresql, sqlite, mysql, sql server',\n",
       " 's3, postgresql, mysql, sql server, sqlite',\n",
       " 'snowflake, sql server, azure blob storage',\n",
       " 'elaticsearch',\n",
       " 'datomic, google bigquery, databricks, s3, splunk',\n",
       " 'google bigquery, mysql, mariadb',\n",
       " 'sqlite, mongodb, sql server',\n",
       " 'amazon athena, mariadb, mysql, s3',\n",
       " 'oracle, amazon athena, amazon redshift, sql server, postgresql',\n",
       " 's3, google bigquery, splunk, dynamodb, databricks',\n",
       " 'snowflake, odbc',\n",
       " 'amazon aurora ou rds, s3',\n",
       " 'oracle, sql server',\n",
       " 'databricks, amazon redshift',\n",
       " 'sql server, databricks',\n",
       " 'db2, sap hana, google bigquery',\n",
       " 's3, databricks',\n",
       " 'databricks, mongodb, oracle, mysql',\n",
       " 'oracle, mysql, sql server',\n",
       " 'google bigquery, google firestore, mysql',\n",
       " 'dremio',\n",
       " 'dynamodb, hive, sql server, db2, hbase',\n",
       " 'mysql, sqlite, sql server',\n",
       " 'snowflake, s3, sas',\n",
       " 'teradata',\n",
       " 'sql server, amazon redshift, mysql',\n",
       " 's3, mysql, amazon aurora ou rds, sql server, postgresql',\n",
       " 'postgresql, s3, amazon redshift',\n",
       " 'sap hana, oracle, sql server',\n",
       " 'dynamodb, mongodb, amazon athena, databricks, mysql, hive',\n",
       " 'mysql, amazon aurora ou rds, amazon athena, amazon redshift, snowflake, mongodb, postgresql, s3',\n",
       " 'oracle, db2',\n",
       " 'mysql, mariadb, dynamodb, amazon redshift, amazon aurora ou rds',\n",
       " 'snowflake, s3, sql server',\n",
       " 'databricks, sql server, oracle, sqlite',\n",
       " 'hive, mariadb, sql server, mysql, mongodb',\n",
       " 'redis, s3, dynamodb, amazon aurora ou rds, postgresql, oracle, mysql, hbase, elaticsearch, sqlite, mongodb, mariadb, amazon athena, amazon redshift',\n",
       " 'google bigquery, postgresql, gcs',\n",
       " 'bigquery',\n",
       " 'google bigquery, sql server, sybase',\n",
       " 's3, postgresql, redis, mongodb',\n",
       " 'mongodb, postgresql',\n",
       " 'oracle, redis, postgresql',\n",
       " 'sql server, oracle, postgresql',\n",
       " 'oracle, amazon athena, mysql, google bigquery',\n",
       " 'google bigquery, amazon redshift, amazon athena, s3',\n",
       " 'oracle, databricks, sql server, s3, google bigquery',\n",
       " 'amazon redshift, postgresql',\n",
       " 'mysql, databricks, mongodb, s3',\n",
       " 'postgresql, sql server, mysql',\n",
       " 'amazon athena, s3, postgresql',\n",
       " 'db2, mongodb, sql server, google bigquery, databricks',\n",
       " 'postgresql, s3, databricks',\n",
       " 's3, sql server, databricks, amazon redshift',\n",
       " 'amazon athena, s3',\n",
       " 'midias sociais',\n",
       " 'oracle, postgresql',\n",
       " 'google bigquery, oracle, microsoft access, mysql, sqlite',\n",
       " 'oracle, mysql, sqlite, sql server',\n",
       " 'hive',\n",
       " 'mysql, oracle',\n",
       " 's3, postgresql, databricks, sql server',\n",
       " 'mysql, sql server, s3, postgresql',\n",
       " 'sql server, redis',\n",
       " 'amazon redshift, mysql, google bigquery, postgresql, s3, firebase',\n",
       " 'sqlite, sql server',\n",
       " 'postgresql, oracle, sql server',\n",
       " 'snowflake, mongodb, databricks',\n",
       " 'sql server, postgresql, mysql',\n",
       " 's3, mariadb, mysql, redis, postgresql, amazon aurora ou rds',\n",
       " 'google firestore, mysql, postgresql',\n",
       " 'mariadb, mysql',\n",
       " 's3, snowflake, postgresql, mysql',\n",
       " 'postgresql, sql server, databricks, oracle, mysql',\n",
       " 's3, mysql',\n",
       " 'lista do sharepoint',\n",
       " 'oracle, s3, postgresql, amazon athena, amazon redshift, splunk',\n",
       " 'sql server, mongodb, amazon athena',\n",
       " 'sap hana, databricks',\n",
       " 'sybase, sql server, mysql, firebird',\n",
       " 'sql server, mysql, google bigquery, databricks',\n",
       " 'databricks, hive',\n",
       " 'mysql, microsoft access',\n",
       " 'amazon athena, sql server, s3',\n",
       " 'google bigquery, dynamodb, amazon aurora ou rds, amazon redshift, sql server, hive, postgresql, amazon athena',\n",
       " 's3, postgresql, mysql, databricks',\n",
       " 'oracle, hive',\n",
       " 'databricks, sql server, sap hana, oracle, elaticsearch',\n",
       " 'firebase, google bigquery, postgresql',\n",
       " 'sql server, hive',\n",
       " 'google bigquery, s3, mysql, sql server',\n",
       " 'sqlite, db2, sql server, s3, amazon athena, coachdb',\n",
       " 'postgresql, google bigquery',\n",
       " 'google bigquery, mongodb',\n",
       " 'postgresql, amazon athena, databricks, dynamodb, snowflake, amazon aurora ou rds, hive, s3, sql server, mysql',\n",
       " 'sql server, mongodb',\n",
       " 'firebase, databricks',\n",
       " 'redis',\n",
       " 'hive, db2, mysql',\n",
       " 'mongodb, postgresql, splunk, sql server, oracle, s3, hive',\n",
       " 'hive, db2',\n",
       " 'firebase, amazon redshift, postgresql, dynamodb, redis, amazon athena, mongodb',\n",
       " 'sap ecc',\n",
       " 'presto, banco de dados próprio da empresa',\n",
       " 'sql server, postgresql',\n",
       " 's3, google bigquery, postgresql, amazon aurora ou rds, sql server, mariadb, amazon redshift, mysql',\n",
       " 's3, sql server, sap hana, google bigquery, mongodb, postgresql, amazon redshift, firebase, mysql, oracle, hive, amazon athena, databricks, presto',\n",
       " 'postgresql, sql server, google bigquery',\n",
       " 'sql server, microsoft access, mysql',\n",
       " 'hive, google bigquery',\n",
       " 'mysql, s3, amazon redshift, postgresql, sqlite, amazon athena, sql server',\n",
       " 'google bigquery, postgresql, s3, elaticsearch',\n",
       " 'mysql, amazon redshift',\n",
       " 's3, snowflake, databricks',\n",
       " 'amazon redshift, s3, amazon athena, databricks',\n",
       " 's3, amazon redshift, postgresql',\n",
       " 'sql server, postgresql, presto, snowflake, databricks, sqlite',\n",
       " 'hive, excel',\n",
       " 'postgresql, snowflake',\n",
       " 'postgresql, amazon redshift, mongodb',\n",
       " 'snowflake, databricks',\n",
       " 'denodo',\n",
       " 'coachdb',\n",
       " 'google bigquery, amazon redshift, mongodb, s3, elaticsearch, postgresql, mysql',\n",
       " 's3, amazon athena, mysql',\n",
       " 'hive, sql server',\n",
       " 'google bigquery, databricks',\n",
       " 'postgresql, firebird, mariadb',\n",
       " 'receita',\n",
       " 'postgresql, elaticsearch',\n",
       " 'mysql, google bigquery, mongodb, postgresql, elaticsearch',\n",
       " 'google bigquery, sql server, redis',\n",
       " 'databricks, amazon athena, amazon redshift, s3',\n",
       " 'mysql, google bigquery, postgresql',\n",
       " 'databricks, mongodb, sql server',\n",
       " 'db2, databricks',\n",
       " 'mysql, dynamodb, amazon redshift, mongodb',\n",
       " 'mysql, presto, google bigquery, google firestore, amazon athena, amazon redshift, firebase, snowflake, databricks, postgresql, sql server, mongodb',\n",
       " 'mysql, postgresql, amazon aurora ou rds, amazon redshift, s3',\n",
       " 'snowflake, postgresql, amazon athena',\n",
       " 'mysql, amazon athena, s3, sqlite, amazon redshift',\n",
       " 'oracle, s3',\n",
       " 'amazon redshift, databricks',\n",
       " 'postgresql, amazon athena, databricks, mysql, s3',\n",
       " 'amazon redshift, amazon athena, s3, postgresql, mysql, presto',\n",
       " 'azure data lake',\n",
       " 'postgresql, amazon redshift, oracle, s3',\n",
       " 'google bigquery, sql server',\n",
       " 'sql server, oracle, mysql',\n",
       " 'amazon athena, postgresql, s3, amazon redshift',\n",
       " 'snowflake, amazon athena, s3',\n",
       " 'sql server, amazon aurora ou rds, mysql',\n",
       " 'sqlite, s3, amazon athena, postgresql, amazon aurora ou rds',\n",
       " 'sql server, microsoft access, oracle',\n",
       " 'google bigquery, databricks, datomic, oracle, s3',\n",
       " 'snowflake, s3',\n",
       " 'databricks, postgresql, sql server',\n",
       " 'databricks, s3, dynamodb, amazon redshift, sql server',\n",
       " 'presto, sql server',\n",
       " 'amazon athena, mysql',\n",
       " 'snowflake, mongodb, coachdb, google bigquery, elaticsearch, postgresql, databricks, mysql',\n",
       " 'sql server, vertica, oracle',\n",
       " 'mongodb, splunk, snowflake',\n",
       " 'amazon athena, s3, google bigquery',\n",
       " 'amazon athena, sql server, mysql, amazon redshift, s3, databricks, postgresql',\n",
       " 's3, postgresql, amazon redshift',\n",
       " 'sqlite, mysql',\n",
       " 'sql server, amazon athena, s3',\n",
       " 'amazon athena, databricks, s3',\n",
       " 'sql server, amazon athena, mysql, amazon redshift, postgresql',\n",
       " 'presto',\n",
       " 'sql server, elaticsearch',\n",
       " 'fontes da empresa em html ou csv',\n",
       " 'sql server, databricks, sap hana',\n",
       " 'snowflake, oracle, postgresql, amazon athena, s3, mongodb',\n",
       " 'databricks, sql server, mysql, postgresql, sap hana',\n",
       " 's3, sql server, mongodb, amazon aurora ou rds, databricks, postgresql, mysql',\n",
       " 'amazon redshift, google bigquery, mongodb, mysql',\n",
       " 'postgresql, google bigquery, elaticsearch',\n",
       " 'firebase, mysql, google bigquery, postgresql, databricks, snowflake, mongodb',\n",
       " 's3, hive, mysql, amazon athena, postgresql, databricks, mongodb, google bigquery, amazon redshift, amazon aurora ou rds',\n",
       " 'sql server, amazon aurora ou rds, mysql, oracle, elaticsearch, postgresql, amazon redshift, databricks, s3, mongodb, amazon athena',\n",
       " 'postgresql, amazon aurora ou rds, db2, hive, splunk, sql server, amazon athena, google bigquery, oracle, s3, amazon redshift, databricks, mysql, snowflake',\n",
       " 'postgresql, amazon redshift, google bigquery, sql server, oracle, databricks',\n",
       " 'postgresql, sql server, elaticsearch, s3',\n",
       " 'elaticsearch, mongodb, postgresql, clickhouse',\n",
       " 'snowflake, databricks, amazon athena',\n",
       " 'sqlite, microsoft access, postgresql, sql server',\n",
       " 'python',\n",
       " 'presto, postgresql',\n",
       " 'mariadb, google firestore',\n",
       " 'amazon redshift, amazon athena, s3',\n",
       " 'microsoft access, snowflake, google bigquery',\n",
       " 'sap hana, snowflake, s3, cassandra, postgresql',\n",
       " 'google bigquery, sybase, oracle, databricks, mysql',\n",
       " 'dynamodb',\n",
       " 'db2',\n",
       " 'google bigquery, mysql, mariadb, s3, postgresql, sql server, sqlite, amazon athena, amazon redshift, snowflake, databricks, oracle',\n",
       " 'snowflake, s3, elaticsearch, dynamodb, redis',\n",
       " 'amazon aurora ou rds, mariadb, amazon athena',\n",
       " 'elaticsearch, sql server, oracle, mysql',\n",
       " 'google bigquery, amazon athena, s3, postgresql',\n",
       " 'databricks, s3, mongodb, postgresql, mysql',\n",
       " 'sap hana, google bigquery, sql server',\n",
       " 'sql server, hana',\n",
       " 'db2, mysql, sql server',\n",
       " 'databricks, firebase, sas libs',\n",
       " 's3, postgresql, google bigquery, hive, amazon redshift',\n",
       " 'databricks, amazon athena, hive',\n",
       " 'sap',\n",
       " 'google bigquery, sql server, postgresql',\n",
       " 'sybase, s3, hive, oracle, sql server',\n",
       " 'mongodb, postgresql, amazon redshift',\n",
       " 's3, amazon redshift, amazon athena, presto',\n",
       " 'mongodb, s3, redis, cassandra, elaticsearch, mariadb',\n",
       " 'mysql, s3, hive, dynamodb, sql server, postgresql, amazon aurora ou rds',\n",
       " 'sqlite, microsoft access, postgresql',\n",
       " 'microsoft access, hive, sql server',\n",
       " 'sql server, sqlite, databricks',\n",
       " 'sql server, s3, mysql, mongodb, sqlite, db2, google bigquery, postgresql, oracle, firebird',\n",
       " 'databricks, postgresql, mysql',\n",
       " 'mysql, sql server, firebird',\n",
       " 'google sheets',\n",
       " 'sql server, firebase, google bigquery, amazon redshift, amazon aurora ou rds, splunk',\n",
       " 'mysql, databricks, s3',\n",
       " 'prefiro não informar',\n",
       " 'hbase, sql server, hive',\n",
       " 'dynamodb, amazon aurora ou rds, s3, amazon athena',\n",
       " 'snowflake, databricks, s3, sql server',\n",
       " 'amazon aurora ou rds, mysql, sql server, postgresql, cassandra, hive',\n",
       " 'google bigquery, s3, hive, presto',\n",
       " 'dynamodb, sqlite, s3, mysql, mongodb, postgresql',\n",
       " 'google bigquery, db2',\n",
       " 'amazon athena, dynamodb, oracle, mongodb, amazon redshift, elaticsearch, amazon aurora ou rds, s3, postgresql',\n",
       " 's3, oracle, databricks, google bigquery',\n",
       " 'mysql, mongodb, sql server, sqlite, postgresql',\n",
       " 'microsoft access, sqlite, sql server, mysql',\n",
       " 'sql server, mongodb, hbase, cassandra, google bigquery, sqlite, amazon athena, amazon aurora ou rds, amazon redshift, hive, db2, dynamodb, databricks, postgresql, mysql, s3, oracle, mariadb, microsoft access',\n",
       " 'postgresql, amazon redshift, amazon athena, mongodb, mysql, amazon aurora ou rds, s3, presto',\n",
       " 'mysql, google bigquery, snowflake, mongodb, neo4j, elaticsearch, s3, presto, postgresql',\n",
       " 'databricks, mongodb, s3, sql server',\n",
       " 'postgresql, splunk, s3',\n",
       " 'microsoft access, mysql, sql server, postgresql',\n",
       " 'mysql, hive, databricks, snowflake, amazon redshift, amazon aurora ou rds',\n",
       " 'amazon athena, sql server',\n",
       " 'databricks, mysql, google bigquery',\n",
       " 'sap hana, oracle, google bigquery',\n",
       " 'amazon redshift, sql server, mysql, mongodb',\n",
       " 'amazon athena, mongodb, mysql, databricks',\n",
       " 'google firestore, postgresql, sql server, google bigquery, mysql, microsoft access',\n",
       " 'mysql, presto, redis, dynamodb, s3, oracle, amazon athena, postgresql, amazon redshift, hive',\n",
       " 'db2, hive',\n",
       " 'google bigquery, s3, mysql, sql server, amazon athena, amazon redshift, presto, postgresql',\n",
       " 'splunk, s3, databricks, dynamodb, datomic',\n",
       " 'postgresql, mysql, oracle, sql server',\n",
       " 'sql server, databricks, mongodb',\n",
       " 'oracle, sap hana',\n",
       " 's3, presto, hive, cassandra, sql server',\n",
       " 's3, sql server',\n",
       " 'amazon athena, mysql, sql server, amazon aurora ou rds, mongodb, s3',\n",
       " 'oracle, postgresql, s3',\n",
       " 'amazon aurora ou rds, amazon athena, mongodb, microsoft access, amazon redshift, sql server, sap hana, oracle',\n",
       " 'databricks, firebase',\n",
       " 'mysql, amazon athena, amazon redshift, s3, postgresql',\n",
       " 'databricks, google bigquery, postgresql, mysql, hive, splunk',\n",
       " 'oracle, amazon athena, neo4j, s3, amazon aurora ou rds, amazon redshift, mongodb, elaticsearch',\n",
       " 'sql server, postgresql, oracle, s3, hive, mysql',\n",
       " 'google bigquery, mongodb, s3',\n",
       " 'mysql, presto, hive, s3',\n",
       " 'sql server, s3, google bigquery, mongodb, cassandra',\n",
       " 'google bigquery, hive',\n",
       " 'oracle, sqlite, elaticsearch, postgresql',\n",
       " 'amazon athena, presto, google firestore, postgresql, mysql, hive, s3, amazon redshift',\n",
       " 'sap hana, sql server, postgresql',\n",
       " 'sql server, postgresql, mysql, oracle',\n",
       " 'databricks, mongodb, elaticsearch',\n",
       " 'postgresql, amazon redshift, dynamodb, amazon athena, amazon aurora ou rds',\n",
       " 'mongodb, dynamodb, s3, amazon aurora ou rds, postgresql, hive, sql server, amazon redshift, hbase, elaticsearch, sqlite, mysql, amazon athena, google bigquery, databricks',\n",
       " 'amazon athena, mongodb, s3, amazon redshift, google bigquery',\n",
       " 'databricks, google bigquery, s3',\n",
       " 's3, mongodb, mysql, postgresql, databricks',\n",
       " 'databricks, amazon athena, oracle',\n",
       " 'sql server, oracle, mongodb, postgresql, amazon redshift, google bigquery, mysql, databricks',\n",
       " 'amazon redshift, mysql',\n",
       " 'snowflake, databricks, s3',\n",
       " 'elaticsearch, postgresql, amazon athena, google bigquery, amazon aurora ou rds, mysql',\n",
       " 'snowflake, databricks, mongodb',\n",
       " 'presto, amazon redshift, s3',\n",
       " 'databricks, postgresql',\n",
       " 'postgresql, google bigquery, amazon redshift, mysql, s3',\n",
       " 'sql server, google bigquery',\n",
       " 'sap hana, mysql, google bigquery',\n",
       " 'postgresql, mysql, sql server, s3',\n",
       " 'microsoft access, mysql, sql server',\n",
       " 'oracle, sas',\n",
       " 'mysql, mariadb, redis, s3, sqlite, postgresql, presto, splunk',\n",
       " 'databricks, snowflake',\n",
       " 'mongodb, google bigquery, amazon athena, databricks',\n",
       " 'sqlite, elaticsearch',\n",
       " 'hive, mysql, postgresql, mongodb, db2, oracle, amazon athena, sql server, s3',\n",
       " 'sql server, amazon athena, mysql, postgresql',\n",
       " 'sap hana, postgresql, firebird, oracle, sql server, s3',\n",
       " 'mysql, s3, sql server, mongodb, postgresql, elaticsearch',\n",
       " 'amazon aurora ou rds',\n",
       " 'mysql, sybase, sql server, google bigquery, microsoft access',\n",
       " 'amazon redshift, postgresql, hive, amazon aurora ou rds, presto, amazon athena, s3',\n",
       " 'dynamodb, amazon redshift, presto, s3, amazon athena, elaticsearch',\n",
       " 'mysql, sql server, oracle',\n",
       " 'cassandra, amazon athena, mariadb, hive, sybase, splunk, sql server, mongodb',\n",
       " 'sql server, postgresql, databricks, mongodb',\n",
       " 'postgresql, firebase, elaticsearch',\n",
       " 'mongodb, dynamodb',\n",
       " 'postgresql, amazon aurora ou rds, sql server, mysql, oracle, amazon athena',\n",
       " 'mysql, mongodb, postgresql, redis, s3, sqlite',\n",
       " 'google bigquery, sap hana, dynamodb, postgresql, sql server',\n",
       " 'oracle, sql server, postgresql',\n",
       " 'sap hana, microsoft access',\n",
       " 'mysql, google bigquery',\n",
       " 'db2, sql server, databricks, mongodb',\n",
       " 'sql server, splunk, hive',\n",
       " 's3, databricks, sql server, oracle, amazon redshift, mysql',\n",
       " 'mysql, redis, s3, elaticsearch, amazon athena, postgresql',\n",
       " 'amazon athena, dynamodb, s3, hive',\n",
       " 'hive, google bigquery, hbase, s3',\n",
       " 'amazon redshift, s3, amazon athena',\n",
       " 'databricks, sap hana, sql server',\n",
       " 'sql server, postgresql, databricks, sqlite',\n",
       " 'amazon athena, amazon redshift, s3',\n",
       " 'postgresql, amazon athena, s3',\n",
       " 'neo4j, mysql, postgresql',\n",
       " 'hive, amazon athena, s3',\n",
       " 'amazon athena, amazon redshift',\n",
       " 'oracle, mysql, firebase, postgresql, snowflake, sap hana',\n",
       " 'sql server, s3, dynamodb, amazon athena, oracle, postgresql, presto, amazon redshift',\n",
       " 'mongodb, postgresql, oracle',\n",
       " 'sql server, mysql, google bigquery, amazon aurora ou rds, oracle, amazon athena',\n",
       " 'mysql, s3, mongodb',\n",
       " 'databricks, mysql, sql server',\n",
       " 'postgresql, dynamodb, databricks, sql server, s3',\n",
       " 'amazon athena, mysql, presto',\n",
       " 'postgresql, mongodb, elaticsearch',\n",
       " 'sql server, mysql, postgresql',\n",
       " 'oracle, neo4j',\n",
       " 'mongodb, mysql, postgresql',\n",
       " 's3, mysql, mongodb, sqlite',\n",
       " 'oracle, mysql, amazon redshift',\n",
       " 'sas',\n",
       " 'mysql, sqlite, databricks, s3, postgresql, amazon athena, sql server, mongodb, google bigquery',\n",
       " 'elaticsearch, cassandra, databricks, s3, amazon athena, hive',\n",
       " 'mysql, sql server, databricks',\n",
       " 'oracle, mysql, mariadb, google bigquery',\n",
       " 'databricks, datomic, google bigquery',\n",
       " 'mysql, google bigquery, oracle, hive, sql server, postgresql, presto',\n",
       " 'redis, amazon athena, mysql, sql server, mariadb, s3, presto',\n",
       " 'snowflake, oracle',\n",
       " 'hive, presto, postgresql, sql server, mysql, s3',\n",
       " 'databricks, snowflake, amazon athena',\n",
       " 'hive, postgresql, db2, mysql, splunk',\n",
       " 'sql server, sqlite',\n",
       " 'mysql, hive, databricks, postgresql, splunk, s3, presto, amazon redshift, google bigquery',\n",
       " 'postgresql, oracle',\n",
       " 'oracle, sql server, sap hana',\n",
       " 'databricks, s3, snowflake',\n",
       " 'sql server, mysql, google bigquery, postgresql',\n",
       " 'amazon athena, mysql, postgresql, s3, databricks',\n",
       " 'elaticsearch, sap hana, oracle, mysql',\n",
       " 'postgresql, google bigquery, sql server, mongodb, oracle',\n",
       " 'db2, google bigquery, sap hana',\n",
       " 'amazon athena, sybase, amazon redshift, dynamodb',\n",
       " 's3, mongodb, postgresql, mysql',\n",
       " 'mysql, sap',\n",
       " 's3, redis, postgresql, sql server, amazon aurora ou rds, databricks, mysql, amazon athena, hive',\n",
       " 's3, sql server, hive, presto, google bigquery',\n",
       " 'sap hana, sqlite, mongodb, databricks, postgresql, sql server, oracle, mysql, mariadb',\n",
       " 'google bigquery, postgresql, databricks, s3',\n",
       " 'oracle, mariadb, s3, presto',\n",
       " 'databricks, s3, postgresql, presto, sqlite, hive, azure blob storage',\n",
       " 'snowflake, mariadb, s3, sqlite, mongodb, postgresql, amazon aurora ou rds, presto, amazon redshift, amazon athena, google bigquery, mysql',\n",
       " 'base interna',\n",
       " 'sql server, s3',\n",
       " 'sql server, oracle, databricks',\n",
       " 'databricks, amazon redshift, oracle, postgresql, google bigquery, s3, mongodb, mysql, sql server',\n",
       " 'postgresql, hive, mysql, s3, amazon athena, dynamodb, redis',\n",
       " 'sql server, postgresql, oracle',\n",
       " 'mongodb, redis',\n",
       " 's3, postgresql, neo4j',\n",
       " 'mongodb, sqlite, s3, mariadb, sql server, mysql',\n",
       " 'hive, sql server, db2, postgresql, mysql, sqlite',\n",
       " 'google bigquery, mongodb, sap hana',\n",
       " 'google bigquery, postgresql, databricks, hive, sql server, mysql, sqlite',\n",
       " 'google bigquery, oracle, amazon redshift',\n",
       " 'dados geoespaciais',\n",
       " 'sql server, oracle, mongodb, vertica',\n",
       " 'hive, oracle',\n",
       " 'amazon athena, postgresql, firebase, mysql',\n",
       " 'amazon redshift, sql server, mysql, databricks, oracle, s3, postgresql',\n",
       " 'amazon aurora ou rds, google bigquery, s3, postgresql, amazon redshift, dynamodb',\n",
       " 'postgresql, amazon redshift',\n",
       " 'databricks, amazon athena, s3',\n",
       " 'amazon athena, google bigquery, snowflake, hive, sql server, db2',\n",
       " 'ibm informix',\n",
       " 'sap hana, sql server, oracle, databricks, informix',\n",
       " 'redis, mysql, oracle, sql server',\n",
       " 'databricks, dynamodb, s3',\n",
       " 'sql server, google bigquery, postgresql, oracle, databricks',\n",
       " 'elaticsearch, postgresql, mysql',\n",
       " 'mysql, sap hana',\n",
       " 'sql server, amazon athena',\n",
       " 'postgresql, mysql, sql server, azure sql',\n",
       " 'databricks, amazon redshift, mysql, s3, google bigquery',\n",
       " 'databricks, hive, sql server',\n",
       " 'google bigquery, oracle, databricks, mongodb',\n",
       " 'dynamodb, hive, databricks, s3',\n",
       " 'google bigquery, gcs',\n",
       " 'google bigquery, google firestore, hive, firebase, databricks, elaticsearch, mongodb, mysql, oracle, s3, sql server, azure storage account',\n",
       " 'mongodb, s3',\n",
       " 'mysql, sqlite, s3, sql server, postgresql',\n",
       " 's3, presto, amazon athena, dynamodb',\n",
       " 'mongodb, mysql, databricks',\n",
       " 'amazon redshift, postgresql, s3, oracle',\n",
       " 'postgresql, amazon redshift, google bigquery, mysql, s3, gcs',\n",
       " 'google bigquery, mysql, google cloud storage',\n",
       " 'databricks, firebase, google bigquery, presto, oracle',\n",
       " 'postgresql, sap hana, s3, mysql, sql server, google bigquery, oracle, mongodb',\n",
       " 'amazon redshift, s3, sap hana, mysql',\n",
       " 's3, mysql, dremio',\n",
       " 'sql server, snowflake, oracle',\n",
       " 'amazon athena, s3, dynamodb',\n",
       " 's3, databricks, snowflake, postgresql, redis, dynamodb',\n",
       " 'databricks, cassandra',\n",
       " 'google bigquery, postgresql, amazon athena, oracle, hive, databricks, s3, mysql, hbase',\n",
       " 'postgresql, sql server, sqlite, mariadb, mongodb, mysql, google bigquery',\n",
       " 'sql server, google bigquery, oracle, mariadb',\n",
       " 'amazon athena, postgresql, mongodb',\n",
       " 'mongodb, databricks, hive, postgresql, amazon redshift, snowflake, presto, s3',\n",
       " 'sqlite, mysql, sql server, postgresql, databricks',\n",
       " 'postgresql, redis, google bigquery, mongodb',\n",
       " 'mysql, sqlite, oracle',\n",
       " 'postgresql, amazon athena',\n",
       " 'sql server, mysql, google bigquery, elaticsearch, hive, databricks',\n",
       " 'oracle, postgresql, firebase',\n",
       " 'databricks, sql server, google bigquery',\n",
       " 'elaticsearch, databricks, sql server',\n",
       " 'databricks, mongodb',\n",
       " 'sql server, sap hana',\n",
       " 'postgresql, hive, databricks, oracle, sqlite, redis',\n",
       " 'sql server, s3, amazon redshift, mysql',\n",
       " 'presto, snowflake, amazon aurora ou rds, dynamodb, amazon athena, s3',\n",
       " 'sqlite, postgresql, mysql, hive, sql server',\n",
       " 'amazon aurora ou rds, sql server, amazon redshift, s3, sqlite, amazon athena, postgresql',\n",
       " 'databricks, oracle',\n",
       " 'oracle, google bigquery, sql server, microsoft access',\n",
       " 'hbase, sql server',\n",
       " 'postgresql, google bigquery, mysql',\n",
       " 'mysql, s3, postgresql, elaticsearch',\n",
       " 'sql server, postgresql, databricks, s3',\n",
       " 'google bigquery, firebase, sap hana, google analytics',\n",
       " 'espaider',\n",
       " 'databricks, amazon aurora ou rds, s3, mongodb, amazon redshift',\n",
       " 'azure',\n",
       " 'sql server, google bigquery, mysql',\n",
       " 'hue',\n",
       " 'mysql, db2',\n",
       " 'hive, hbase, db2',\n",
       " 'oracle, firebird, firebase, microsoft access, postgresql',\n",
       " 'amazon athena, s3, mysql, amazon aurora ou rds',\n",
       " 'sql server, presto, hive, amazon aurora ou rds, elaticsearch, sybase, redis, mariadb, s3, dynamodb, cassandra, amazon athena, amazon redshift, mongodb',\n",
       " 'sql server, oracle, hbase, google bigquery',\n",
       " 'sql server, sas',\n",
       " 's3, oracle, databricks, mysql, coachdb, sql server, amazon athena, google firestore, google bigquery, sqlite',\n",
       " 'google bigquery, sql server, snowflake, sqlite, firebase, amazon redshift, postgresql, databricks, mysql, s3',\n",
       " 'microsoft access, mysql',\n",
       " 'spss',\n",
       " 'google bigquery, firebase, postgresql',\n",
       " 'sql server, sqlite, mysql, oracle, microsoft access, snowflake, postgresql',\n",
       " 'dynamodb, s3',\n",
       " 'snowflake, mongodb, s3',\n",
       " 'sql server, db2, oracle, mysql, postgresql, mariadb',\n",
       " 'sql server, databricks, oracle, excel',\n",
       " 'google bigquery, redis',\n",
       " 'oracle, mongodb',\n",
       " 'mysql, amazon redshift, sql server, postgresql, oracle, databricks, sap hana, mariadb, mongodb, s3',\n",
       " 'sql server, amazon aurora ou rds, mongodb, mysql',\n",
       " 'amazon aurora ou rds, mysql, postgresql, databricks, s3, amazon athena, sql server',\n",
       " 'postgresql, redis, s3',\n",
       " 'mongodb, mysql, sql server, google bigquery, amazon redshift',\n",
       " 'amazon redshift, google bigquery, sql server',\n",
       " 'hive, s3, presto, splunk, dynamodb, sql server, amazon athena, oracle',\n",
       " 'oracle, sql server, snowflake, mysql',\n",
       " 'presto, mysql, s3, dremio',\n",
       " 'databricks, snowflake, oracle, postgresql, sql server, mysql',\n",
       " 'mariadb, postgresql, mysql, amazon redshift',\n",
       " 'postgresql, excel',\n",
       " 'google firestore, firebase, dynamodb',\n",
       " 'amazon redshift, sql server, postgresql, databricks, mongodb',\n",
       " 'postgresql, sqlite, s3, mysql, mongodb',\n",
       " 'mongodb, sqlite',\n",
       " 'mysql, sap hana, db2, google bigquery, firebase',\n",
       " 'databricks, amazon redshift, postgresql, hive, s3, sql server',\n",
       " 's3, postgresql',\n",
       " 'postgresql, mongodb, firebase, redis',\n",
       " 'databricks, sql server, postgresql',\n",
       " 'kobotoolbox',\n",
       " 's3, superset',\n",
       " 'sql server, hive, teradata',\n",
       " 'sqlite, sql server, s3, hive, mysql, amazon athena',\n",
       " 'elaticsearch, postgresql',\n",
       " 'mysql, hive, sqlite',\n",
       " 'sql server, mongodb, cassandra, postgresql, hive, mysql, oracle, databricks',\n",
       " 'google',\n",
       " 'sql server, postgresql, s3, hive, google bigquery',\n",
       " 'sql server, azue blob storage',\n",
       " 'oracle, google bigquery, sql server, postgresql',\n",
       " 'databricks, postgresql, neo4j, elaticsearch, hive',\n",
       " 'postgresql, databricks, sql server, mysql, google bigquery',\n",
       " 'mongodb, google bigquery',\n",
       " 'hive, sql server, splunk, mysql',\n",
       " 'amazon athena, amazon redshift, postgresql, s3',\n",
       " 'oracle, sybase',\n",
       " 's3, amazon redshift, postgresql, hive',\n",
       " 'sap hana, snowflake, google bigquery, databricks',\n",
       " 'coachdb, sql server',\n",
       " 'mongodb, postgresql, elaticsearch, redis, dynamodb, google bigquery',\n",
       " 'amazon aurora ou rds, dynamodb, amazon athena, postgresql',\n",
       " 'google bigquery, oracle, mariadb, mysql, sql server',\n",
       " 'amazon redshift, amazon athena',\n",
       " 'google bigquery, postgresql, oracle, sql server, mysql, firebase',\n",
       " 'mysql, sql server, sqlite, postgresql, oracle',\n",
       " 'postgresql, mongodb',\n",
       " 'redis, mysql, google bigquery, mongodb, s3',\n",
       " 'google bigquery, sql server, amazon redshift, postgresql',\n",
       " 's3, databricks, postgresql, cassandra',\n",
       " 'informix',\n",
       " 'postgresql, snowflake, sqlite, amazon redshift, google bigquery, microsoft access, databricks, mysql',\n",
       " 'sql server, oracle, mongodb',\n",
       " 's3, redis, oracle, databricks',\n",
       " 'oracle, postgresql, mysql, sql server',\n",
       " 's3, mysql, mongodb',\n",
       " 'google bigquery, mysql, sap hana, s3, postgresql, sql server, mongodb',\n",
       " 'postgresql, databricks, s3',\n",
       " 'sap hana, sql server',\n",
       " 'microsoft access, databricks',\n",
       " 'oracle, mysql, postgresql',\n",
       " 'databricks, amazon athena, s3, elaticsearch',\n",
       " 'postgresql, firebase',\n",
       " 'sql server, mongodb, mysql, presto, databricks, snowflake, elaticsearch, amazon athena',\n",
       " 'postgresql, amazon athena, s3, amazon redshift, google bigquery',\n",
       " 'outro',\n",
       " 'mysql, oracle, postgresql, microsoft access, db2, elaticsearch, hive',\n",
       " 'sql server, mongodb, oracle',\n",
       " 'postgresql, sql server, firebird',\n",
       " 'databricks, snowflake, postgresql, presto, s3, amazon athena',\n",
       " 'mongodb, databricks, postgresql, presto, amazon redshift, s3, amazon athena',\n",
       " 's3, dynamodb, amazon athena, postgresql, mongodb, mysql, databricks, elaticsearch, amazon aurora ou rds, hive, amazon redshift',\n",
       " 'databricks, firebase, postgresql, s3',\n",
       " 'redis, databricks, mongodb, sql server',\n",
       " 'mongodb, mysql',\n",
       " 'sql server, mariadb, postgresql, cassandra, s3, google bigquery, databricks, google firestore, hive',\n",
       " 'postgresql, databricks, amazon redshift, mysql, amazon athena',\n",
       " 'sqlite, google bigquery, postgresql, sql server, mysql, microsoft access, s3',\n",
       " 'ooo',\n",
       " 'sql server, oracle, elaticsearch, amazon athena, postgresql, clickhouse',\n",
       " 'postgresql, s3, mongodb',\n",
       " 'google bigquery, sql server, mysql, postgresql, google firestore',\n",
       " 'postgresql, snowflake, databricks, google bigquery, amazon redshift',\n",
       " 'amazon redshift, presto',\n",
       " 's3, mysql, oracle',\n",
       " 'splunk, dbeaver',\n",
       " 'oracle, sharepoint',\n",
       " 'postgresql, redis, s3, amazon aurora ou rds, amazon athena, hive',\n",
       " 'postgresql, mariadb, mysql, neo4j, oracle',\n",
       " 'amazon aurora ou rds, google bigquery, postgresql, mongodb',\n",
       " 's3, mysql, mongodb, postgresql',\n",
       " 'db2, redis, google bigquery, sap hana',\n",
       " 'databricks, presto, postgresql, amazon redshift, hive',\n",
       " 'amazon redshift, amazon athena, presto',\n",
       " 'redis, google bigquery, postgresql',\n",
       " 's3, postgresql, elaticsearch, amazon aurora ou rds, redis',\n",
       " 'amazon athena, s3, elaticsearch, postgresql, dynamodb, mongodb, amazon redshift, sql server, mysql',\n",
       " 'mariadb, oracle, dynamodb, amazon athena, mongodb, mysql, amazon redshift, amazon aurora ou rds',\n",
       " 'postgresql, sql server, hive',\n",
       " 'snowflake, databricks, sql server, oracle',\n",
       " 'databricks, sql server, snowflake, s3, google big query, azure adls, azure synapse',\n",
       " 'mysql, s3, mongodb, postgresql, cassandra',\n",
       " 'sql server, s3, databricks, mongodb, google bigquery',\n",
       " 'sql server, oracle, postgresql, sap hana',\n",
       " 'mysql, sap hana, sql server, google bigquery',\n",
       " 'sql server, postgresql, oracle, databricks',\n",
       " 'sqlite, sql server, dynamodb',\n",
       " 'oracle, mongodb, mysql, sql server, mariadb, postgresql',\n",
       " 'mongodb, google bigquery, snowflake',\n",
       " 'oracle, sql server, presto, s3, amazon athena',\n",
       " 'microsoft access, oracle, mysql, sql server, sqlite',\n",
       " 'google bigquery, sql server, azure',\n",
       " 'google bigquery, db2, amazon redshift, firebase, databricks, sql server, amazon athena',\n",
       " 's3, amazon athena, sql server',\n",
       " 'elaticsearch, sqlite, redis, mysql, hive',\n",
       " 'amazon redshift, databricks, amazon athena, mongodb, postgresql, s3, dynamodb',\n",
       " 'sap hana, oracle, sql server, microsoft access',\n",
       " 'google bigquery, sql server, postgresql, mysql',\n",
       " 'sql server, mysql, medidata rave',\n",
       " 'google bigquery, neo4j, presto, postgresql, hive, hbase, mysql',\n",
       " 's3, amazon athena, postgresql, sql server, mysql',\n",
       " 'dados alternativos e dados internos da empresa',\n",
       " 'sql server, oracle, hive',\n",
       " 'sqlite, microsoft access, mysql',\n",
       " 'google bigquery, postgresql, sql server',\n",
       " 'google bigquery, firebase',\n",
       " 'postgresql, hive, mongodb, mysql, oracle, db2, redis',\n",
       " 'postgresql, amazon athena, mysql, s3, dynamodb, amazon redshift, presto, sql server, mongodb',\n",
       " 'redis, dynamodb, amazon redshift',\n",
       " 'google bigquery, mysql, sap hana, postgresql, sql server, amazon athena',\n",
       " 'sql server, mongodb, google bigquery, databricks, sap hana, microsoft access',\n",
       " 'databricks, hive, s3, sql server',\n",
       " 'sql server, oracle, hive, databricks',\n",
       " 'databricks, hive, sap hana, sql server, db2',\n",
       " 'amazon aurora ou rds, sqlite, db2, hive',\n",
       " 'elaticsearch, postgresql, google bigquery',\n",
       " 'sql server, databricks, microsoft access',\n",
       " 'b.o sap',\n",
       " 'amazon athena, sql server, amazon redshift, s3',\n",
       " 'sql server, dataflow',\n",
       " 'sap hana, google bigquery, mariadb, postgresql, oracle, mysql',\n",
       " 'omie',\n",
       " 'amazon aurora ou rds, dynamodb, amazon athena, mysql, sql server, databricks, mariadb, amazon redshift, s3, postgresql, firebird, google bigquery, mongodb, hive',\n",
       " 's3, elaticsearch, amazon athena, sql server',\n",
       " 'amazon aurora ou rds, postgresql, amazon redshift, s3, dynamodb',\n",
       " 'oracle, postgresql, mysql',\n",
       " 'sql server, google bigquery, databricks',\n",
       " 'snowflake, s3, databricks',\n",
       " 'postgresql, db2, snowflake',\n",
       " 'sybase',\n",
       " 'firebase, mysql, google bigquery, postgresql',\n",
       " 'postgresql, databricks',\n",
       " 'mysql, mongodb',\n",
       " 'mysql, sqlite, oracle, sql server, postgresql',\n",
       " 'google bigquery, redis, amazon athena',\n",
       " 'sql server, ms azure',\n",
       " 'mariadb, elaticsearch, sqlite, mysql, postgresql',\n",
       " 'sqlite, mongodb',\n",
       " 'sql server, oracle, amazon redshift',\n",
       " 'mysql, amazon aurora ou rds',\n",
       " 'postgresql, hive',\n",
       " 'hive, amazon aurora ou rds, sql server',\n",
       " 'sql server, amazon athena, microsoft access',\n",
       " 'postgresql, dynamodb, snowflake, s3, mongodb, mysql, amazon aurora ou rds',\n",
       " 'oracle, databricks, postgresql, sql server, mysql, microsoft access',\n",
       " 's3, splunk, mariadb, mysql',\n",
       " 'postgresql, amazon athena, mongodb',\n",
       " 'sql server, synapse',\n",
       " 'postgresql, elaticsearch, google bigquery, bigtable',\n",
       " 'postgresql, google bigquery, sql server, mongodb',\n",
       " 'amazon aurora ou rds, mysql, dynamodb, s3, postgresql',\n",
       " 'elaticsearch, mysql, s3, microsoft access',\n",
       " 'google bigquery, sql server, databricks, oracle, s3',\n",
       " 'oracle, sqlite, duckdb',\n",
       " 'elaticsearch, postgresql, google bigquery, mariadb, mysql, databricks, firebird, oracle, amazon athena, s3, dynamodb, snowflake, sql server, presto, splunk',\n",
       " 'elaticsearch, sql server, amazon athena, mysql, oracle',\n",
       " 'google bigquery, mysql, sqlite, postgresql, s3',\n",
       " 'sap hana, postgresql, sql server, google bigquery, s3',\n",
       " 'postgresql, amazon redshift, s3, mysql, amazon athena',\n",
       " 'sql server, mysql, oracle',\n",
       " 'postgresql, sql server, oracle, mysql',\n",
       " 'mongodb, databricks',\n",
       " 'firebird, postgresql, microsoft access, mysql, sql server',\n",
       " 'splunk, sql server, s3, amazon aurora ou rds',\n",
       " 'cassandra, s3, amazon redshift, amazon athena, dynamodb',\n",
       " 'sql server, mysql, sqlite',\n",
       " 's3, mysql, mariadb, amazon aurora ou rds',\n",
       " 'amazon athena, mongodb, databricks, google bigquery, postgresql, hive, oracle',\n",
       " 'google bigquery, mysql, amazon redshift',\n",
       " 'databricks, presto',\n",
       " 'firebase, google bigquery',\n",
       " 'mysql, amazon athena, postgresql, google bigquery, sql server, db2',\n",
       " 'mongodb, mysql, mariadb',\n",
       " 'amazon redshift, mysql, mongodb, postgresql, firebase, elaticsearch, sap hana, google bigquery, dynamodb',\n",
       " 'snowflake, mysql',\n",
       " 'mysql, oracle, databricks, sql server',\n",
       " 'oracle, hive, amazon athena, google bigquery, amazon redshift, presto, snowflake, postgresql, s3, sql server',\n",
       " 'databricks, sql server, sap hana, mysql',\n",
       " 'sql server, mysql, sap hana, snowflake',\n",
       " 'postgresql, mariadb, firebird, mysql, oracle, sql server',\n",
       " 'amazon athena, amazon redshift, s3, dynamodb',\n",
       " 'mysql, amazon athena, amazon redshift, databricks',\n",
       " 'microsoft access, sql server, postgresql',\n",
       " 'postgresql, firebird, db2, sql server, sybase, sqlite, mysql, oracle',\n",
       " 'oracle, s3, snowflake',\n",
       " 'cognos',\n",
       " 'amazon redshift, oracle',\n",
       " 'redis, postgresql, sqlite, firebase',\n",
       " 'elaticsearch, mongodb, postgresql',\n",
       " 'snowflake, microsoft access',\n",
       " 'db2, google firestore, mysql, sql server, postgresql, google bigquery',\n",
       " 'postgresql, s3, elaticsearch',\n",
       " 'databricks, sql server, mysql, s3, amazon redshift',\n",
       " 'sql server, dynamodb, oracle, google bigquery, splunk',\n",
       " 'sql server, hive, postgresql',\n",
       " 'amazon athena, databricks, presto, postgresql, google bigquery',\n",
       " 'mongodb, postgresql, hive, databricks, mysql, elaticsearch',\n",
       " 'elaticsearch, neo4j, amazon athena, postgresql, amazon aurora ou rds, presto',\n",
       " 'mysql, s3, postgresql, oracle, sql server, webscraping',\n",
       " 'oracle, amazon athena, amazon redshift, amazon aurora ou rds, s3, postgresql',\n",
       " 'amazon athena, amazon aurora ou rds, dynamodb, amazon redshift, s3',\n",
       " 'amazon redshift, google bigquery, sap hana, s3',\n",
       " 'databricks, mongodb, s3, elaticsearch',\n",
       " 'sql server, sap hana, snowflake, oracle, sybase',\n",
       " 'google bigquery, amazon redshift, postgresql',\n",
       " 's3, dynamodb, amazon redshift, google bigquery',\n",
       " 'presto, sql server, mysql, mongodb, databricks, s3, google bigquery, sqlite, hive, postgresql',\n",
       " 'amazon aurora ou rds, sqlite, mysql, postgresql',\n",
       " 'sql server, mysql, databricks, sap hana',\n",
       " 'amazon athena, sql server, postgresql, amazon redshift',\n",
       " 's3, amazon athena, amazon redshift, dynamodb, sap hana, google bigquery',\n",
       " 'google bigquery, mysql, mongodb',\n",
       " 'google bigquery, amazon athena, amazon redshift, postgresql, snowflake, databricks, s3, mysql, presto, sap hana',\n",
       " 'google bigquery, mongodb, sap hana, postgresql',\n",
       " 'amazon aurora ou rds, oracle, sql server',\n",
       " 'mysql, s3',\n",
       " 'sql server, postgresql, mariadb, mysql',\n",
       " 'postgresql, oracle, s3',\n",
       " 'dynamodb, sql server, amazon aurora ou rds, s3, amazon athena, mongodb, snowflake, amazon redshift, mysql, hive, oracle, neo4j, redis',\n",
       " 'mysql, google bigquery, s3',\n",
       " 'firebird, db2, postgresql, sql server',\n",
       " 'hive, amazon athena',\n",
       " 'amazon redshift, s3, databricks, sql server, sybase',\n",
       " 'postgresql, databricks, snowflake',\n",
       " 'sql server, databricks, redis',\n",
       " 'mysql, oracle, firebird',\n",
       " 'sql server, oracle, google firestore',\n",
       " 'google bigquery, oracle',\n",
       " 's3, amazon redshift, sql server, amazon athena, google bigquery',\n",
       " 'google bigquery, oracle, mysql',\n",
       " 'google bigquery, db2, postgresql, amazon redshift, s3, sql server',\n",
       " 'snowflake, databricks, oracle',\n",
       " 'mongodb, postgresql, amazon aurora ou rds, influxdb',\n",
       " 'databricks, mysql',\n",
       " 'elaticsearch, postgresql, firebase, s3, google bigquery, mysql, amazon redshift',\n",
       " 'postgresql, mongodb, firebase',\n",
       " 'sap hana, mongodb, google bigquery',\n",
       " 'mysql, sql server, postgresql, oracle',\n",
       " 'mysql, postgresql, oracle, mariadb',\n",
       " 'sql server, mysql, google bigquery',\n",
       " 'amazon redshift, amazon athena, presto, s3, postgresql, hive, databricks',\n",
       " 'amazon athena, s3, amazon aurora ou rds',\n",
       " 'hive, postgresql, s3',\n",
       " 'postgresql, cassandra, databricks, s3',\n",
       " 'postgresql, s3, oracle',\n",
       " 'databricks, sql server, hbase, hive, mysql, firebase, firebird, amazon athena, oracle, google bigquery',\n",
       " 'mysql, hpcc systems',\n",
       " 'sqlite, mysql, mariadb, hbase, hive, firebird, sql server, oracle, mongodb',\n",
       " 'nosso banco é no excel',\n",
       " 'mysql, sqlite, databricks, sql server',\n",
       " 'oracle, sql server, databricks, amazon redshift',\n",
       " 'google bigquery, s3',\n",
       " 'mysql, sql server, firebase',\n",
       " 'amazon athena, s3, amazon redshift',\n",
       " 'snowflake, postgresql, mysql, oracle',\n",
       " 'splunk, google bigquery, datomic, neo4j, databricks, sqlite, s3',\n",
       " 's3, mysql, db2, amazon redshift, amazon athena',\n",
       " 'amazon athena, databricks, sqlite',\n",
       " 'google bigquery, s3, snowflake, mongodb, mysql, neo4j',\n",
       " 'mysql, presto, databricks, s3, postgresql, cassandra',\n",
       " 'amazon redshift, postgresql, s3, amazon athena',\n",
       " 'mysql, oracle, microsoft access, amazon aurora ou rds',\n",
       " 's3, sql server, oracle',\n",
       " 'postgresql, mysql, oracle',\n",
       " 'oracle, sql server, google bigquery, sqlite, postgresql, mysql, mariadb',\n",
       " 'splunk, dynamodb, postgresql, oracle, firebase',\n",
       " 'mongodb, sql server, redis, amazon redshift, s3, postgresql, amazon athena',\n",
       " 'sqlite, postgresql',\n",
       " 'amazon redshift, amazon athena, oracle, mongodb',\n",
       " 'postgresql, mysql, mongodb, sql server, oracle',\n",
       " 'db2, mysql',\n",
       " 'cassandra, presto, amazon aurora ou rds, s3',\n",
       " 'oracle, teradata',\n",
       " 'amazon athena, presto, amazon aurora ou rds, postgresql, dynamodb, s3',\n",
       " 'mysql, sql server, dynamodb, amazon athena, s3',\n",
       " 'postgresql, amazon athena, hive, presto, s3, mysql, databricks, dynamodb, sql server',\n",
       " 's3, mysql, sql server, oracle, amazon redshift, splunk, vertica',\n",
       " 'mysql, google firestore, sql server, sqlite, mongodb',\n",
       " 'cassandra, databricks',\n",
       " 'dynamodb, s3, snowflake',\n",
       " 'hive, oracle, mysql, db2',\n",
       " 'postgresql, sql server, snowflake',\n",
       " 'elaticsearch, redis, postgresql, mongodb, mysql, firebase, google bigquery, sqlite',\n",
       " 'oracle, sqlite',\n",
       " 'neo4j, s3, mongodb, google bigquery',\n",
       " 's3, amazon aurora ou rds, amazon redshift',\n",
       " 'google bigquery, mongodb, oracle, s3',\n",
       " 's3, mysql, postgresql, oracle',\n",
       " 'microsoft access, snowflake, amazon aurora ou rds, firebase, oracle, postgresql, mysql, amazon athena, databricks, s3, sql server',\n",
       " 'databricks, sybase, postgresql, hive, oracle, sql server',\n",
       " 's3, hive, mongodb, firebase, neo4j, sql server, elaticsearch, presto, google bigquery, amazon aurora ou rds, postgresql',\n",
       " 'amazon athena, google bigquery',\n",
       " 'dados públicos externos',\n",
       " 'mysql, mongodb, hive, s3, amazon athena, databricks, postgresql',\n",
       " 'google bigquery, databricks, sql server',\n",
       " 's3, sql server, mongodb, amazon redshift, amazon athena',\n",
       " 'amazon aurora ou rds, redis, postgresql, s3, amazon athena, google bigquery, mysql',\n",
       " 'amazon aurora ou rds, postgresql',\n",
       " 'amazon redshift, postgresql, mongodb, s3, presto, amazon aurora ou rds, dynamodb, amazon athena, hive',\n",
       " 'datomic, databricks, s3',\n",
       " 'sql server, mysql, mongodb, postgresql, firebird, amazon aurora ou rds, s3, oracle',\n",
       " 's3, amazon athena, dynamodb, splunk, redis, elaticsearch, mongodb, sqlite, google bigquery, postgresql, mysql, presto',\n",
       " 'oracle, amazon redshift, postgresql',\n",
       " 'google bigquery, mysql, oracle, splunk, postgresql',\n",
       " 's3, mongodb, mariadb, amazon redshift, amazon athena, postgresql',\n",
       " 'mysql, sap hana, google bigquery, sql server',\n",
       " 'google bigquery, cassandra, amazon athena, databricks',\n",
       " 'hadoop',\n",
       " 'mysql, sqlite',\n",
       " 'oracle, sql server, redis, firebird',\n",
       " ...]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"bancos_de_dados\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44112b91",
   "metadata": {},
   "source": [
    "## Variáveis Categoricas do dataframe \n",
    "\n",
    "    - nivel_ensino (ordinal) == oneHotEncoder \n",
    "    - tempo_de_experiencia (ordinal) == oneHotEncoder\n",
    "    - genero (nominal) == oneHotEnconder \n",
    "    - etnia (nominal) == OneHotEnconder \n",
    "    - estado_moradia (nominal) == OnehotEnconder\n",
    "    - pcd e vive_no_brasil (binaria) = mapeamento para 0 || 1\n",
    "    \n",
    "    - linguagem_preferidas e bancos_de_dados (OneHotEncoder com CountVectorizer)\n",
    "\n",
    "    - cargo (Vai ser meu target)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738a212",
   "metadata": {},
   "source": [
    "Analisando os valores unicos da coluna \"estado_moradia\", pois é uma das colunas com mais valores unicos e mapeando a fim de diminuir o numero de novas colunas criadas com o OneHotEnconder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca887fbe",
   "metadata": {},
   "source": [
    "## Realizando o Mapeamento Binário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f992a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeia 'Sim' para 1 e 'Não' para 0\n",
    "df['pcd'] = df['pcd'].map({'Sim': 1, 'Não': 0})\n",
    "\n",
    "# Converte True para 1 e False para 0\n",
    "df['vive_no_brasil'] = df['vive_no_brasil'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0684e41",
   "metadata": {},
   "source": [
    "## Realizando o OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f6c4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "colunas_OneHot = ['genero','etnia','formacao','cloud_preferida','estado_moradia','nivel_ensino','tempo_experiencia_dados']\n",
    "\n",
    "encoded_data = encoder.fit_transform(df[colunas_OneHot])\n",
    "\n",
    "new_column_names = encoder.get_feature_names_out(colunas_OneHot)\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=new_column_names, index=df.index)\n",
    "\n",
    "df = pd.concat([df.drop(colunas_OneHot, axis=1), encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb4c50",
   "metadata": {},
   "source": [
    "## Realizando o OneHotEnconde usando o CountVectorizer\n",
    "\n",
    "descrição: utiliza-se o CountVectorizer para realizar o OneHot quando se tem texto e é necessário quebra-lo pra forma novas colunas individuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62f6e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['linguagens_preferidas'] = df['linguagens_preferidas'].fillna('')\n",
    "\n",
    "#Inicializar o CountVectorizer com o token_pattern CORRIGIDO\n",
    "#O padrão r'(?u)\\b\\w+\\b' captura \"palavras\" de 1 ou mais caracteres, incluindo 'r'\n",
    "vectorizer = CountVectorizer(\n",
    "    binary=True,\n",
    "    token_pattern=r'(?u)\\b\\w+\\b'\n",
    ")\n",
    "\n",
    "#Aplicar o vectorizer à coluna para aprender o vocabulário e transformar os dados\n",
    "linguagens_vetorizadas = vectorizer.fit_transform(df['linguagens_preferidas'])\n",
    "\n",
    "#Criar um novo DataFrame com as colunas para cada linguagem\n",
    "linguagens_df = pd.DataFrame(\n",
    "    linguagens_vetorizadas.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out(),\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "df = pd.concat([df.drop('linguagens_preferidas', axis=1), linguagens_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d2474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\morae\\workspace\\jornada\\censo_preditivo\\venv_novo\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df['bancos_de_dados'] = df['bancos_de_dados'].fillna('')\n",
    "\n",
    "sinonimos = {\n",
    "    # Bancos relacionais\n",
    "    \"mysql\": [\"mysql\", \"my sql\", \"my-sql\", \"my_sql\", \"pwa microsoft - mysql ou sql\"],\n",
    "    \"postgresql\": [\"postgres\", \"postgresql\", \"postgre\"],\n",
    "    \"sqlserver\": [\"sql server\", \"sqlserver\", \"ms sql\", \"mssql\", \"sql dbx\"],\n",
    "    \"oracle\": [\"oracle\", \"oracledb\", \"autonomous db\", \"sap hana\", \"hana\"],\n",
    "    \"db2\": [\"db2\"],\n",
    "    \"sqlite\": [\"sqlite\", \"sq lite\"],\n",
    "    \"access\": [\"access\", \"microsoft access\"],\n",
    "    \"mariadb\": [\"mariadb\"],\n",
    "    \"firebird\": [\"firebird\"],\n",
    "    \"informix\": [\"informix\", \"ibm informix\"],\n",
    "\n",
    "    # NoSQL\n",
    "    \"mongodb\": [\"mongodb\", \"mongo db\", \"mongo\"],\n",
    "    \"cassandra\": [\"cassandra\"],\n",
    "    \"document_stores\": [\"cosmos db\", \"couchdb\", \"cruxdb\", \"datomic\", \"dynamodb\", \"firebase\"],\n",
    "    \"graph_db\": [\"neo4j\"],\n",
    "    \"time_series\": [\"influxdb\"],\n",
    "    \"key_value\": [\"redis\"],\n",
    "    \"search_engines\": [\"elasticsearch\", \"solr\"],\n",
    "\n",
    "    # Cloud AWS\n",
    "    \"aws\": [\"amazon aurora\", \"amazon aurora ou rds\", \"aurora\",\n",
    "            \"amazon redshift\", \"redshift\",\n",
    "            \"amazon athena\", \"rds\", \"s3\"],\n",
    "\n",
    "    # Cloud GCP\n",
    "    \"gcp\": [\"bigquery\", \"google bigquery\", \"google big query\",\n",
    "            \"big table\", \"bigtable\",\n",
    "            \"cloud spanner\",\n",
    "            \"google analytics\",\n",
    "            \"google cloud storage\", \"gcs\",\n",
    "            \"google firestore\",\n",
    "            \"google sheets\",\n",
    "            \"google\"],\n",
    "\n",
    "    # Cloud Azure\n",
    "    \"azure\": [\"azure\", \"ms azure\",\n",
    "              \"azure sql\",\n",
    "              \"azure synapse\", \"synapse\",\n",
    "              \"azure blob storage\", \"azue blob storage\",\n",
    "              \"azure data lake\", \"azure adls\",\n",
    "              \"azure data explorer\",\n",
    "              \"azure storage account\"],\n",
    "\n",
    "    # Plataformas/Lakes/ETL\n",
    "    \"data_lakes\": [\"databricks\", \"databricks sql\",\n",
    "                   \"deltalake\", \"denodo\", \"dremio\", \"dali - hpcc system\", \"hpcc systems\"],\n",
    "    \"bi_tools\": [\"cognos\", \"sap bo\", \"microstrategy\", \"powerbi\", \"superset\",\n",
    "                 \"tableau\", \"sas\", \"sas libs\", \"spss\", \"splunk\", \"metabase\"],\n",
    "    \"dev_tools\": [\"dbeaver\", \"knime\", \"kobotoolbox\", \"espaider\"],\n",
    "\n",
    "    # Arquivos / Formatos\n",
    "    \"arquivos\": [\".csv\", \"bases excel e csv extraídas direto no site\", \"excel\",\n",
    "                 \"nosso banco é no excel\", \"odbc\", \"office\"],\n",
    "\n",
    "    # Dados internos / externos\n",
    "    \"dados_internos\": [\n",
    "        \"dados internos\", \"dados não estruturados\", \"base interna\",\n",
    "        \"base de dados local\", \"dados alternativos e dados internos da empresa\",\n",
    "        \"banco de dados próprio da empresa\", \"fontes internas e de clientes\",\n",
    "        \"fontes da empresa em html ou csv\", \"interno\"\n",
    "    ],\n",
    "    \"dados_publicos\": [\"dados públicos externos\", \"datasus\", \"receita\"],\n",
    "    \"dados_geoespaciais\": [\"dados geoespaciais\"],\n",
    "    \"web_apis\": [\"api\", \"consumo de apis com azure functions\", \"webscraping\"],\n",
    "    \"midias_digitais\": [\"diversas fontes de marketing digital\", \"midias sociais\", \"rd station\", \"salesforce\", \"omie\", \"crm\", \"sistema de crm\"],\n",
    "\n",
    "    # SAP\n",
    "    \"sap\": [\"sap\", \"sap ecc\", \"sap business\", \"sap hana\"],\n",
    "\n",
    "    # Big Data / Processamento\n",
    "    \"big_data\": [\"hadoop\", \"hive\", \"hbase\", \"impala\", \"presto\", \"vertica\", \"teradata\", \"snowflake\", \"splunk\", \"hue\", \"ibm blue mix\"],\n",
    "\n",
    "    # Outros\n",
    "    \"lista_sharepoint\": [\"lista do sharepoint\", \"sharepoint\"],\n",
    "    \"pesquisa_empirica\": [\"pesquisas empírica que eu coleto os dados\"],\n",
    "    \"prefiro_nao_informar\": [\"prefiro não informar\"],\n",
    "    \"nao_uso\": [\"não uso\"],\n",
    "    \"outro\": [\"outro\", \"solução proprietária\", \"ooo\", \"nsa\", \"sintax\"],\n",
    "    \"python\": [\"python\"],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Função para normalizar\n",
    "def normalizar_nome(nome):\n",
    "    nome = nome.strip().lower()\n",
    "    for padrao, variantes in sinonimos.items():\n",
    "        if nome in variantes:\n",
    "            return padrao\n",
    "    return nome  # se não bater, mantém\n",
    "\n",
    "# Quebrar por vírgula, limpar e normalizar\n",
    "def preprocessar_bancos(texto):\n",
    "    itens = [item.strip() for item in texto.split(',')]\n",
    "    return \",\".join([normalizar_nome(item) for item in itens if item])\n",
    "\n",
    "df['bancos_de_dados'] = df['bancos_de_dados'].apply(preprocessar_bancos)\n",
    "\n",
    "# Tokenizer customizado\n",
    "custom_tokenizer = lambda text: [item.strip() for item in text.split(',')]\n",
    "\n",
    "# Vectorizer\n",
    "vectorizer_db = CountVectorizer(\n",
    "    binary=True,\n",
    "    tokenizer=custom_tokenizer\n",
    ")\n",
    "\n",
    "db_vetorizados = vectorizer_db.fit_transform(df['bancos_de_dados'])\n",
    "\n",
    "bancos_df = pd.DataFrame(\n",
    "    db_vetorizados.toarray(),\n",
    "    columns=vectorizer_db.get_feature_names_out(),\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "# Concatenar de volta\n",
    "df = pd.concat([df.drop('bancos_de_dados', axis=1), bancos_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47d3f1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idade</th>\n",
       "      <th>pcd</th>\n",
       "      <th>vive_no_brasil</th>\n",
       "      <th>cargo</th>\n",
       "      <th>genero_Feminino</th>\n",
       "      <th>genero_Masculino</th>\n",
       "      <th>genero_Prefiro não informar</th>\n",
       "      <th>etnia_Amarela</th>\n",
       "      <th>etnia_Branca</th>\n",
       "      <th>etnia_Indígena</th>\n",
       "      <th>...</th>\n",
       "      <th>progress</th>\n",
       "      <th>python</th>\n",
       "      <th>sap</th>\n",
       "      <th>search_engines</th>\n",
       "      <th>sql</th>\n",
       "      <th>sqlite</th>\n",
       "      <th>sqlserver</th>\n",
       "      <th>sybase</th>\n",
       "      <th>time_series</th>\n",
       "      <th>web_apis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DBA/Administrador de Banco de Dados</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Desenvolvedor/ Engenheiro de Software/ Analist...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cientista de Dados/Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Desenvolvedor/ Engenheiro de Software/ Analist...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Professor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Analista de Marketing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Analista de Dados/Data Analyst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Engenheiro de Dados/Arquiteto de Dados/Data En...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Outra Opção</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Analista de Dados/Data Analyst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2981 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      idade  pcd  vive_no_brasil  \\\n",
       "0        39  0.0               1   \n",
       "1        53  0.0               1   \n",
       "2        27  0.0               1   \n",
       "3        46  0.0               1   \n",
       "4        32  0.0               1   \n",
       "...     ...  ...             ...   \n",
       "2976     28  0.0               1   \n",
       "2977     26  0.0               1   \n",
       "2978     30  0.0               1   \n",
       "2979     31  0.0               1   \n",
       "2980     24  0.0               1   \n",
       "\n",
       "                                                  cargo  genero_Feminino  \\\n",
       "0                   DBA/Administrador de Banco de Dados              0.0   \n",
       "1     Desenvolvedor/ Engenheiro de Software/ Analist...              0.0   \n",
       "2                     Cientista de Dados/Data Scientist              0.0   \n",
       "3     Desenvolvedor/ Engenheiro de Software/ Analist...              1.0   \n",
       "4                                             Professor              1.0   \n",
       "...                                                 ...              ...   \n",
       "2976                              Analista de Marketing              0.0   \n",
       "2977                     Analista de Dados/Data Analyst              0.0   \n",
       "2978  Engenheiro de Dados/Arquiteto de Dados/Data En...              1.0   \n",
       "2979                                        Outra Opção              0.0   \n",
       "2980                     Analista de Dados/Data Analyst              0.0   \n",
       "\n",
       "      genero_Masculino  genero_Prefiro não informar  etnia_Amarela  \\\n",
       "0                  1.0                          0.0            0.0   \n",
       "1                  1.0                          0.0            0.0   \n",
       "2                  1.0                          0.0            0.0   \n",
       "3                  0.0                          0.0            0.0   \n",
       "4                  0.0                          0.0            0.0   \n",
       "...                ...                          ...            ...   \n",
       "2976               1.0                          0.0            0.0   \n",
       "2977               1.0                          0.0            0.0   \n",
       "2978               0.0                          0.0            0.0   \n",
       "2979               1.0                          0.0            0.0   \n",
       "2980               1.0                          0.0            0.0   \n",
       "\n",
       "      etnia_Branca  etnia_Indígena  ...  progress  python  sap  \\\n",
       "0              0.0             0.0  ...         0       0    0   \n",
       "1              1.0             0.0  ...         0       0    0   \n",
       "2              1.0             0.0  ...         0       0    0   \n",
       "3              1.0             0.0  ...         0       0    0   \n",
       "4              0.0             0.0  ...         0       0    0   \n",
       "...            ...             ...  ...       ...     ...  ...   \n",
       "2976           1.0             0.0  ...         0       0    0   \n",
       "2977           1.0             0.0  ...         0       0    0   \n",
       "2978           1.0             0.0  ...         0       0    0   \n",
       "2979           1.0             0.0  ...         0       0    0   \n",
       "2980           1.0             0.0  ...         0       0    0   \n",
       "\n",
       "      search_engines  sql  sqlite  sqlserver  sybase  time_series  web_apis  \n",
       "0                  0    0       0          1       0            0         0  \n",
       "1                  0    0       0          0       0            0         0  \n",
       "2                  0    0       0          0       0            0         0  \n",
       "3                  0    0       0          0       0            0         0  \n",
       "4                  0    0       0          0       0            0         0  \n",
       "...              ...  ...     ...        ...     ...          ...       ...  \n",
       "2976               0    0       1          0       0            0         0  \n",
       "2977               0    0       0          0       0            0         0  \n",
       "2978               0    0       0          1       0            0         0  \n",
       "2979               0    0       0          0       0            0         0  \n",
       "2980               0    0       0          1       0            0         0  \n",
       "\n",
       "[2981 rows x 137 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66511e6b",
   "metadata": {},
   "source": [
    "## Normalizando Dados e comparativo estatistico da coluna idade antes e depois da normalização "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec9aff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "idade_antes_normalizada = df['idade'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "377397b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_para_normalizar = ['idade']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[colunas_para_normalizar] = scaler.fit_transform(df[colunas_para_normalizar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00fabf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "idade_depois_normalizada = df['idade'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "70ab4172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antes da Normalizacao (Idade em anos)</th>\n",
       "      <th>Depois da Normalizacao (0 a 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2981.000000</td>\n",
       "      <td>2981.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.334452</td>\n",
       "      <td>0.342624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.439328</td>\n",
       "      <td>0.178870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Antes da Normalizacao (Idade em anos)  Depois da Normalizacao (0 a 1)\n",
       "count                            2981.000000                     2981.000000\n",
       "mean                               30.334452                        0.342624\n",
       "std                                 6.439328                        0.178870\n",
       "min                                18.000000                        0.000000\n",
       "25%                                26.000000                        0.222222\n",
       "50%                                29.000000                        0.305556\n",
       "75%                                34.000000                        0.444444\n",
       "max                                54.000000                        1.000000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_comparativa = pd.DataFrame({\n",
    "    'Antes da Normalizacao (Idade em anos)': idade_antes_normalizada,\n",
    "    'Depois da Normalizacao (0 a 1)': idade_depois_normalizada\n",
    "})\n",
    "\n",
    "matriz_comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f92a33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['idade',\n",
       " 'pcd',\n",
       " 'vive_no_brasil',\n",
       " 'cargo',\n",
       " 'genero_Feminino',\n",
       " 'genero_Masculino',\n",
       " 'genero_Prefiro não informar',\n",
       " 'etnia_Amarela',\n",
       " 'etnia_Branca',\n",
       " 'etnia_Indígena',\n",
       " 'etnia_Outra',\n",
       " 'etnia_Parda',\n",
       " 'etnia_Prefiro não informar',\n",
       " 'etnia_Preta',\n",
       " 'formacao_Ciências Biológicas/ Farmácia/ Medicina/ Área da Saúde',\n",
       " 'formacao_Ciências Sociais',\n",
       " 'formacao_Computação / Engenharia de Software / Sistemas de Informação/ TI',\n",
       " 'formacao_Economia/ Administração / Contabilidade / Finanças/ Negócios',\n",
       " 'formacao_Estatística/ Matemática / Matemática Computacional/ Ciências Atuariais',\n",
       " 'formacao_Marketing / Publicidade / Comunicação / Jornalismo',\n",
       " 'formacao_Outra opção',\n",
       " 'formacao_Outras Engenharias',\n",
       " 'formacao_Prefiro não informar',\n",
       " 'formacao_Química / Física',\n",
       " 'cloud_preferida_Amazon Web Services (AWS)',\n",
       " 'cloud_preferida_Azure (Microsoft)',\n",
       " 'cloud_preferida_Google Cloud (GCP)',\n",
       " 'cloud_preferida_Não sei opinar',\n",
       " 'cloud_preferida_Outra Cloud',\n",
       " 'estado_moradia_Alagoas (AL)',\n",
       " 'estado_moradia_Amazonas (AM)',\n",
       " 'estado_moradia_Bahia (BA)',\n",
       " 'estado_moradia_Ceará (CE)',\n",
       " 'estado_moradia_Distrito Federal (DF)',\n",
       " 'estado_moradia_Espírito Santo (ES)',\n",
       " 'estado_moradia_Goiás (GO)',\n",
       " 'estado_moradia_Maranhão (MA)',\n",
       " 'estado_moradia_Mato Grosso (MT)',\n",
       " 'estado_moradia_Mato Grosso do Sul (MS)',\n",
       " 'estado_moradia_Minas Gerais (MG)',\n",
       " 'estado_moradia_Não Informado',\n",
       " 'estado_moradia_Paraná (PR)',\n",
       " 'estado_moradia_Paraíba (PB)',\n",
       " 'estado_moradia_Pará (PA)',\n",
       " 'estado_moradia_Pernambuco (PE)',\n",
       " 'estado_moradia_Piauí (PI)',\n",
       " 'estado_moradia_Rio Grande do Norte (RN)',\n",
       " 'estado_moradia_Rio Grande do Sul (RS)',\n",
       " 'estado_moradia_Rio de Janeiro (RJ)',\n",
       " 'estado_moradia_Santa Catarina (SC)',\n",
       " 'estado_moradia_Sergipe (SE)',\n",
       " 'estado_moradia_São Paulo (SP)',\n",
       " 'nivel_ensino_Doutorado ou Phd',\n",
       " 'nivel_ensino_Estudante de Graduação',\n",
       " 'nivel_ensino_Graduação/Bacharelado',\n",
       " 'nivel_ensino_Mestrado',\n",
       " 'nivel_ensino_Não tenho graduação formal',\n",
       " 'nivel_ensino_Prefiro não informar',\n",
       " 'nivel_ensino_Pós-graduação',\n",
       " 'tempo_experiencia_dados_Mais de 10 anos',\n",
       " 'tempo_experiencia_dados_Menos de 1 ano',\n",
       " 'tempo_experiencia_dados_Não tenho experiência na área de dados',\n",
       " 'tempo_experiencia_dados_de 1 a 2 anos',\n",
       " 'tempo_experiencia_dados_de 3 a 4 anos',\n",
       " 'tempo_experiencia_dados_de 4 a 6 anos',\n",
       " 'tempo_experiencia_dados_de 7 a 10 anos',\n",
       " 'c',\n",
       " 'clojure',\n",
       " 'dax',\n",
       " 'elixir',\n",
       " 'excel',\n",
       " 'go',\n",
       " 'java',\n",
       " 'javascript',\n",
       " 'julia',\n",
       " 'language',\n",
       " 'm',\n",
       " 'não',\n",
       " 'opinar',\n",
       " 'postegres',\n",
       " 'pyspark',\n",
       " 'python',\n",
       " 'r',\n",
       " 'rust',\n",
       " 'sas',\n",
       " 'scala',\n",
       " 'sei',\n",
       " 'spark',\n",
       " 'sql',\n",
       " 'vba',\n",
       " 'access',\n",
       " 'arquivos',\n",
       " 'aws',\n",
       " 'azure',\n",
       " 'b.o sap',\n",
       " 'bi_tools',\n",
       " 'big_data',\n",
       " 'cassandra',\n",
       " 'clickhouse',\n",
       " 'coachdb',\n",
       " 'dados_geoespaciais',\n",
       " 'dados_internos',\n",
       " 'dados_publicos',\n",
       " 'data_lakes',\n",
       " 'dataflow',\n",
       " 'db2',\n",
       " 'dev_tools',\n",
       " 'document_stores',\n",
       " 'duckdb',\n",
       " 'elaticsearch',\n",
       " 'firebird',\n",
       " 'gcp',\n",
       " 'graph_db',\n",
       " 'informix',\n",
       " 'key_value',\n",
       " 'lista_sharepoint',\n",
       " 'mariadb',\n",
       " 'medidata rave',\n",
       " 'midias_digitais',\n",
       " 'mongodb',\n",
       " 'mysql',\n",
       " 'nao_uso',\n",
       " 'oracle',\n",
       " 'outro',\n",
       " 'pesquisa_empirica',\n",
       " 'postgresql',\n",
       " 'prefiro_nao_informar',\n",
       " 'progress',\n",
       " 'python',\n",
       " 'sap',\n",
       " 'search_engines',\n",
       " 'sql',\n",
       " 'sqlite',\n",
       " 'sqlserver',\n",
       " 'sybase',\n",
       " 'time_series',\n",
       " 'web_apis']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2c7d9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('../data/sods_processado.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_novo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
